{"name":"Schoenberg","tagline":"generating atonality with a markov chain","body":"# AI Project1: Music Generator\r\n_**Eleanor Wright** - Coordinator_    \r\n_**Gray Leonard** - Implementor_    \r\n_**Sean Yang** - Documentor_    \r\n\r\n### Overview\r\nOur goal for this project was to create an AI that generates samples of music based on the user's emotional preferences (happy or sad). Originally, we were trying to get more options for user preferences, but we decided to use user preferences of happy or sad because it was easier to evaluate.    \r\n**Here are two examples:**    \r\n1. [Happy Song](https://raw.githubusercontent.com/sy5578a/AI_Project1/master/happy.mid)   \r\n2. [Sad Song](https://raw.githubusercontent.com/sy5578a/AI_Project1/master/sad.mid)\r\n### Design and Technical Approach\r\nFor this AI project, we used hierarchical Markov chains to create music from existing midi files. (For more information on how  we implemented Hierarchical Markov Chains to create music, read page 2 of [Project Report](https://docs.google.com/a/student.american.edu/document/d/1aVQ9spoQZrY9aDc02oYDLmwgUVtAgeupX_iMpO_akRo/edit#)).    \r\nTo share our source codes, we used Git because we were able to edit, review, import and export documents easily among our group members.    \r\n### Evaluation\r\nWe did a survey using a sample of happy and sample of sad song. About 96% said that the happy song was happy and 80% thought the sad song was sad; therefor, we have a successful AI. Because the music generator is somewhat random, it is difficult to create a music generator AI that can mimic everyone's interpretations of music, but we successfully manage to create a decent AI.    \r\n    \r\n_To see our codes click \"View on GitHub\" on the top right corner of this page_ ","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}